Очевидные проблемы - разное время отработки запросов к API страховых компаний.  
Необходимо опросить 5 внешних сервисов, потом полученные данные агрегировать. Несмотря на то, что частота запросов не высокая 
(раз в 15 минут и 1 раз в сутки), но сильная зависимость одного сервиса от скорости работы как внешних источников, так и других сервисов, 
делает текущую архитектуру довольно ненадежной.  
На любом из этих этапов что-то может "сломаться", или время ответа будет слишком большим, или ответа вообще не будет.  
Для синхронного взаимодействия это может стать фатальным. Сервис инициатор может ничего не получить в 
ответ, либо получить неполные данные.

Попытаемся "развязать" сервисы используя асинхронный характер взаимодействия между сервисами.
Возможные решения, тезисно
- **сервис `ins-product-aggregator`** запрашивает информацию о продуктах и тарифах от страховых, агрегирует в единый список. 

Так как каждый REST API страховых может функционировать по своим SLA (или не функционировать вовсе) то логично было бы 
опрашивать эти внешние источники с той периодичность, которая для них приемлема либо оговорена в партнерском договоре. 
Далее полученные данные "сливать" в единый pipeline.
В рамках данного pipeline новые данные объединяются в общий список продуктов. Новые элементы добавляются, старые меняются или удаляются.

После обновления данных по продуктам можно опубликовать его заинтересованным сторонам. Для этого можно использовать одну из доступных 
реализаций Event Streaming, остановимся на Kafka.

- **сервис `core-app`** запрашивает данные о продуктах и тарифах у сервиса `ins-product-aggregator`. 

После того как сервис `ins-product-aggregator` стал публиковать события с подготовленными данными по продуктам, сервис
`core-app` может подписаться на эти события и получать обновления почти сразу после того, как изменения произошли и сохранять их в свою БД.
Сохранение в БД позволит получать эти данные в любой момент, а не только раз в 15 минут, а также при перезапуске сервиса данные 
по последним состояниям продуктов/тарифов не будут потеряны. 

Также данный сервис формируем событие при оформлении новой страховки и публикует его в ту же Kafka.
Событие оформления страховки является критически важным для бизнеса, поэтому необходимо гарантировать его сохранность и дистрибуцию до других 
заинтересованных потребителей. В данном случае целесообразно было бы применить паттерн Transactional Outbox, чтобы гарантировать 
что событие действительно будет сформировано при новой страховке, и не будет отправлено если создание страховки завершится неудачей. 

- **сервис `ins-comp-settlement`** раз в сутки опрашивает `core-app` на предмет новых страховых оформлений за день

Теперь так как оформление новой страховки публикуется в Kafka, данный сервис подписывается на эти события и при получении, сохраняет метаинформацию в
свою базу данных, в удобном для себя формате. При генерации отчета, данные выгружаются из БД, вместо запроса сервису `ins-product-aggregator`.

Эти данные также позволят формировать реестр всех оформленных страховок просто выгружая всё из БД, не делая ночных запросов, ведь они в течение дня будут 
сохраняться в локальной реплике. Единственный момент в данной ситуации, необходимо будет мигрировать данные в локальную 
реплику сервиса `ins-comp-settlement` старых страховок, оформленных до момента внедрения асинхронного подхода.

